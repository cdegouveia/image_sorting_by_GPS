{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# IPHOTO ALBUM (& NAS) DOWNLOAD TOOL & KML PARSER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### This tool downloads a local copy of a specified and authenticated iCloud photo album or NAS storage. After generating the local duplicate, the tool scans each image and compiles an inventory, incorporating GPS data. The inventory, complete with GPS coordinates, is saved as a CSV file. This file is then be parsed to identify photos taken within locations or projects defined by KML polygons exported from Google Earth. The tool then copies the identified photos into project-specific folders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: START HERE TO LOAD MODULES AND BUILD SUB-ROUTINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from exif import Image\n",
    "import os\n",
    "import io\n",
    "import pyicloud\n",
    "from pyicloud import PyiCloudService\n",
    "import geopandas as gpd\n",
    "import time\n",
    "import csv\n",
    "from PIL import Image as PILImage\n",
    "from pillow_heif import HeifImagePlugin\n",
    "from PIL import ExifTags\n",
    "import hashlib\n",
    "import shutil\n",
    "import fiona\n",
    "from shapely.geometry import Point, Polygon\n",
    "import pandas as pd\n",
    "from csv import reader\n",
    "fiona.drvsupport.supported_drivers['KML'] = 'rw'\n",
    "\n",
    "def icloud_initiate(username = \"\", password = \"\"):\n",
    "    # Authenticate with your iCloud account\n",
    "    api = PyiCloudService(username, password)\n",
    "    if api.requires_2fa:\n",
    "        print(\"Two-factor authentication required.\")\n",
    "        code = input(\"Enter the code you received of one of your approved devices: \")\n",
    "        result = api.validate_2fa_code(code)\n",
    "        print(\"Code validation result: %s\" % result)\n",
    "        if not result:\n",
    "            print(\"Failed to verify security code\")\n",
    "            sys.exit(1)\n",
    "        if not api.is_trusted_session:\n",
    "            print(\"Session is not trusted. Requesting trust...\")\n",
    "            result = api.trust_session()\n",
    "            print(\"Session trust result %s\" % result)\n",
    "            if not result:\n",
    "                print(\"Failed to request trust. You will likely be prompted for the code again in the coming weeks\")\n",
    "    elif api.requires_2sa:\n",
    "        import click\n",
    "        print(\"Two-step authentication required. Your trusted devices are:\")\n",
    "        devices = api.trusted_devices\n",
    "        for i, device in enumerate(devices):\n",
    "            print(\n",
    "                \"  %s: %s\" % (i, device.get('deviceName',\n",
    "                \"SMS to %s\" % device.get('phoneNumber')))\n",
    "            )\n",
    "        device = click.prompt('Which device would you like to use?', default=0)\n",
    "        device = devices[device]\n",
    "        if not api.send_verification_code(device):\n",
    "            print(\"Failed to send verification code\")\n",
    "            sys.exit(1)\n",
    "        code = click.prompt('Please enter validation code')\n",
    "        if not api.validate_verification_code(device, code):\n",
    "            print(\"Failed to verify verification code\")\n",
    "            sys.exit(1)\n",
    "    return(api)\n",
    "\n",
    "def download_missing_icloud_photos(destination_folder = \"\", api=\"\"):\n",
    "    tic = time.perf_counter()\n",
    "    photos = api.photos.all\n",
    "    files_checked_count = 0\n",
    "    new_files_found_count = 0\n",
    "    files_downloaded_list = []\n",
    "    total_count = len(photos)\n",
    "    local_file_list=[]\n",
    "    for file in os.listdir(destination_folder):\n",
    "        local_file_list.append(os.path.splitext(file)[0])\n",
    "    for photo in photos:\n",
    "        files_checked_count +=1\n",
    "        file_extension = os.path.splitext(photo.filename)\n",
    "        new_filename = format(photo.created.timestamp(),\".3f\") + file_extension[1]\n",
    "        photo_filename = os.path.join(destination_folder, new_filename)\n",
    "        if os.path.splitext(new_filename)[0] in local_file_list:\n",
    "            pass\n",
    "        else:\n",
    "            new_files_found_count +=1\n",
    "            image_data = photo.download().content\n",
    "            try:\n",
    "                img = PILImage.open(io.BytesIO(image_data))\n",
    "                image_exif = img.getexif()\n",
    "                image_exif[0xA300] = \"iCloud\"\n",
    "                img.save(photo_filename, exif= image_exif)\n",
    "            except:\n",
    "                with open(photo_filename, 'wb') as opened_file:\n",
    "                    opened_file.write(image_data)\n",
    "            files_downloaded_list.append(photo_filename)\n",
    "        print(\"New iPhotos found on icloud = \" + str(new_files_found_count) + \" (Checking: \" + str(files_checked_count) + \" of \" + str(total_count) + \")\", end =\"\\r\")\n",
    "    print(\"\\nMissing photos download done! Now run 'quick_photo_csv' or 'full_photo_csv'.\")\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Time taken: {(toc - tic)/60:0.4f} minutes\")\n",
    "    return(files_downloaded_list)\n",
    "\n",
    "def download_new_icloud_photos(destination_folder = \"\", api=\"\"):\n",
    "    photos = api.photos.all\n",
    "    files_checked_count = 0\n",
    "    new_files_found_count = 0\n",
    "    existing_files_found_count = 0\n",
    "    files_downloaded_list = []\n",
    "    total_count = len(photos)\n",
    "    local_file_list=[]\n",
    "    for file in os.listdir(destination_folder):\n",
    "        local_file_list.append(os.path.splitext(file)[0])\n",
    "    for photo in photos:\n",
    "        files_checked_count +=1\n",
    "        file_extension = os.path.splitext(photo.filename)\n",
    "        new_filename = format(photo.created.timestamp(),\".3f\") + file_extension[1]\n",
    "        photo_filename = os.path.join(destination_folder, new_filename)\n",
    "        if os.path.splitext(new_filename)[0] in local_file_list:\n",
    "            existing_files_found_count += 1\n",
    "            pass\n",
    "        else:\n",
    "            new_files_found_count +=1\n",
    "            existing_files_found_count = 0\n",
    "            image_data = photo.download().content\n",
    "            try:\n",
    "                img = PILImage.open(io.BytesIO(image_data))\n",
    "                image_exif = img.getexif()\n",
    "                image_exif[0xA300] = \"iCloud\"\n",
    "                img.save(photo_filename, exif= image_exif)\n",
    "            except:\n",
    "                with open(photo_filename, 'wb') as opened_file:\n",
    "                    opened_file.write(image_data)\n",
    "            files_downloaded_list.append(photo_filename)\n",
    "        print(\"New iPhotos found on icloud = \" + str(new_files_found_count) + \" (Checking: \" + str(files_checked_count) + \" of \" + str(total_count) + \")\", end =\"\\r\")\n",
    "        if existing_files_found_count > 1000:\n",
    "            break\n",
    "    print(\"\\nNew photos download done! Now run 'quick_photo_csv' or 'full_photo_csv'.\")\n",
    "    return(files_downloaded_list)\n",
    "\n",
    "def download_all_icloud_photos_again(destination_folder = \"\", api=\"\"):\n",
    "    tic = time.perf_counter()\n",
    "    exist_file_count = len(os.listdir(destination_folder))\n",
    "    photos = api.photos.all\n",
    "    files_downloaded_count = 0\n",
    "    files_downloaded_list =[]\n",
    "    total_count = len(photos)\n",
    "    for photo in photos:\n",
    "        files_downloaded_count +=1\n",
    "        if files_downloaded_count < (exist_file_count - 5):\n",
    "            print(\"iPhoto already downloaded count = \" + str(files_downloaded_count), end =\"\\r\")\n",
    "            continue\n",
    "        file_extension = os.path.splitext(photo.filename)\n",
    "        new_filename = format(photo.created.timestamp(),\".3f\") + file_extension[1]\n",
    "        photo_filename = os.path.join(destination_folder, new_filename)\n",
    "        image_data = photo.download().content\n",
    "        try:\n",
    "            img = PILImage.open(io.BytesIO(image_data))\n",
    "            image_exif = img.getexif()\n",
    "            image_exif[0xA300] = \"iCloud\"\n",
    "            img.save(photo_filename, exif= image_exif)\n",
    "        except:\n",
    "            with open(photo_filename, 'wb') as opened_file:\n",
    "                opened_file.write(image_data)\n",
    "        files_downloaded_list.append(photo_filename)\n",
    "        print(\"iPhotos downloaded from icloud = \" + str(files_downloaded_count) + \" of \" + str(total_count), end =\"\\r\")\n",
    "    print(\"\\niCloud photos full download complete! Now run 'quick_photo_csv' or 'full_photo_csv'.\")\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Time taken: {(toc - tic)/60:0.4f} minutes\")\n",
    "    return()\n",
    "\n",
    "def quick_photo_csv(target_folders = []):\n",
    "    print(\"Running quick_photo_csv\")\n",
    "    tic = time.perf_counter()\n",
    "    photo_list_file = os.path.join(system_file_location, \"GPS_image_list_master.csv\")\n",
    "    file_list = []\n",
    "    file_list_name = []\n",
    "    if os.path.exists(photo_list_file) != True:\n",
    "        file_list=[[\"File Name\", \"File type\", \"Source location\", \"Date\", \"Lattitude\", \"Longitude\"]]\n",
    "    else:\n",
    "        with open(photo_list_file, 'r') as file:\n",
    "            csvreader = csv.reader(file)\n",
    "            for row in csvreader:\n",
    "                file_list.append(row)\n",
    "                file_list_name.append(row[0])\n",
    "    print(\"Opened 'GPS_image_list_master.csv'. Looking for missed records.\")\n",
    "    files_checked_count = 0\n",
    "    new_files_found = 0\n",
    "    all_filenames_found = []\n",
    "    for folder in target_folders:\n",
    "        for file in get_all_filenames_in_target_folder(folder):\n",
    "            all_filenames_found.append(file)\n",
    "    photo_quantity = len(all_filenames_found)\n",
    "    for photo in all_filenames_found:\n",
    "        files_checked_count +=1\n",
    "        if os.path.splitext(os.path.basename(photo))[0] in file_list_name:\n",
    "            pass\n",
    "        else:\n",
    "            if os.path.splitext(photo)[1] == \".JPEG\" or os.path.splitext(photo)[1] == \".MOV\":\n",
    "                new_files_found +=1\n",
    "                image_exif = get_image_coordinates(photo)\n",
    "                date = image_exif[0]\n",
    "                coords_lat = image_exif[1]\n",
    "                coords_long = image_exif[2]\n",
    "                file_source = photo\n",
    "                full_path = photo\n",
    "                photo = os.path.basename(photo)\n",
    "                new_file=[os.path.splitext(photo)[0],os.path.splitext(photo)[1],file_source, date, coords_lat, coords_long]\n",
    "                file_list.append(new_file)\n",
    "        print(\"Checking file \" + str(files_checked_count) + \" of \" + str(photo_quantity) + \". New JPG or MOV files found = \" + str(new_files_found), end =\"\\r\")\n",
    "    with open(photo_list_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(file_list)\n",
    "    print(\"\\nUpdated photo register written to 'GPS_image_list_master.csv'.\")\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Time taken: {(toc - tic)/60:0.4f} minutes\")\n",
    "    return()\n",
    "\n",
    "def full_photo_csv(target_folders = []):\n",
    "    tic = time.perf_counter()\n",
    "    print(\"Proceeding to gather info on disk contents. This will take a while.\")\n",
    "    file_list=[[\"File Name\", \"File type\", \"Source location\", \"Date\", \"Lattitude\", \"Longitude\"]]\n",
    "    files_checked_count = 0\n",
    "    all_filenames_found = []\n",
    "    for folder in target_folders:\n",
    "        for file in get_all_filenames_in_target_folder(folder):\n",
    "            all_filenames_found.append(file)\n",
    "    photo_quantity = len(all_filenames_found)\n",
    "    for photo in all_filenames_found:\n",
    "        files_checked_count +=1\n",
    "        if os.path.splitext(photo)[1] == \".JPEG\" or os.path.splitext(photo)[1] == \".MOV\":\n",
    "            image_exif = get_image_coordinates(photo)\n",
    "            date = image_exif[0]\n",
    "            coords_lat = image_exif[1]\n",
    "            coords_long = image_exif[2]\n",
    "            file_source = photo\n",
    "            full_path = photo\n",
    "            photo = os.path.basename(photo)\n",
    "            new_file=[os.path.splitext(photo)[0],os.path.splitext(photo)[1],file_source, date, coords_lat, coords_long]\n",
    "            file_list.append(new_file)\n",
    "        print(\"Photos resolved = \" + str(files_checked_count) + \" of \" + str(photo_quantity), end =\"\\r\")\n",
    "    photo_list_file = os.path.join(system_file_location, \"GPS_image_list_master.csv\")\n",
    "    with open(photo_list_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(file_list)\n",
    "    print(\"\\nNew photo register written to 'GPS_image_list_master.csv'.\")\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Time taken: {(toc - tic)/60:0.4f} minutes\")\n",
    "    return()\n",
    "\n",
    "def get_image_coordinates(image_file):\n",
    "    date = ''\n",
    "    coords_lat = 0\n",
    "    coords_long = 0\n",
    "    file_source = \"\"\n",
    "    try:\n",
    "        with open(image_file, 'rb') as src:\n",
    "            img = Image(src)\n",
    "            date = ''\n",
    "            coords = (0,0)\n",
    "            if img.has_exif:\n",
    "                try:\n",
    "                    pass\n",
    "                    imge = PILImage.open(image_file)\n",
    "                    image_exif = imge.getexif()\n",
    "                    file_source = image_exif[0xA300]\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    date = img.datetime_original\n",
    "                except:\n",
    "                    pass\n",
    "                try:\n",
    "                    coords_lat = decimal_coords(img.gps_latitude,img.gps_latitude_ref)\n",
    "                    coords_long = decimal_coords(img.gps_longitude,img.gps_longitude_ref)\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    except:\n",
    "        if os.path.splitext(image_file)[1] != \".MOV\":\n",
    "            print(\"File may be corrupt: \" + image_file)\n",
    "        pass\n",
    "    return (date, coords_lat, coords_long, file_source)\n",
    "\n",
    "def decimal_coords(coords, ref):\n",
    "    decimal_degrees = coords[0] + coords[1] / 60 + coords[2] / 3600\n",
    "    if ref == 'S' or ref == 'W':\n",
    "        decimal_degrees = -decimal_degrees\n",
    "    return decimal_degrees\n",
    "\n",
    "def convert_images_to_JPEG(target_folder = \"\"):\n",
    "    print(\"Running convert_images_to_JPEG\")\n",
    "    succesful_conversion = 0 \n",
    "    failed_conversion = 0 \n",
    "    files_to_convert=[]\n",
    "    files_not_converted = []\n",
    "    list_of_files = get_all_filenames_in_target_folder(target_folder)\n",
    "    print(\"Analysing folder\")\n",
    "    for file in list_of_files:\n",
    "        file_extension = os.path.splitext(file)[1]\n",
    "        if file_extension != \".JPEG\" and file_extension != \".MOV\":\n",
    "            files_to_convert.append(file)\n",
    "    full_count = len(files_to_convert)\n",
    "    for file_with_path in files_to_convert:\n",
    "        print(\"Files converted to JPEG: \" + str(succesful_conversion) + \" of \" + str(full_count), end =\"\\r\")\n",
    "        if os.path.exists(file_with_path):\n",
    "            file_extension = os.path.splitext(file_with_path)[1]\n",
    "            if file_extension != \".JPEG\" and file_extension != \".MOV\":\n",
    "                new_filename = os.path.splitext(file_with_path)[0] + \".JPEG\"\n",
    "                try:\n",
    "                    #print(path)\n",
    "                    with PILImage.open(file_with_path) as img:\n",
    "                        image_exif = img.getexif()\n",
    "                        img.format = 'jpeg'\n",
    "                        img.save(new_filename, exif= image_exif, quality=75)\n",
    "                        succesful_conversion +=1\n",
    "                    os.remove(file_with_path)\n",
    "                except:\n",
    "                    failed_conversion += 1\n",
    "                    files_not_converted.append(file_with_path)\n",
    "    if len(files_not_converted) != 0:\n",
    "        print(\"\\nFiles that were not converted = \" + str(failed_conversion) + \", moved to \" + unsupported_file_location + \": \")\n",
    "        for file in files_not_converted:\n",
    "            try:\n",
    "                os.rename(file, os.path.join(unsupported_file_location, os.path.basename(file)))\n",
    "            except:\n",
    "                os.remove(os.path.join(unsupported_file_location, os.path.basename(file)))\n",
    "            print(os.path.basename(file))\n",
    "    return()\n",
    "\n",
    "def get_all_filenames_in_target_folder(target_folder = \"\"):\n",
    "    dir_path = target_folder\n",
    "    list_of_files = []\n",
    "    for path in os.listdir(dir_path):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(dir_path, path)):\n",
    "            list_of_files.append(os.path.join(dir_path, path))\n",
    "    print(\"Files found on \" + target_folder + \": \" + str(len(list_of_files)))\n",
    "    return(list_of_files)\n",
    "\n",
    "def get_hash(f_path, mode='md5'):\n",
    "    h = hashlib.new(mode)\n",
    "    with open(f_path, 'rb') as file:\n",
    "        data = file.read()\n",
    "    h.update(data)\n",
    "    digest = h.hexdigest()\n",
    "    return digest\n",
    "\n",
    "def crawl_for_images(destination_folder = \"\", source_locations = []):\n",
    "    tic = time.perf_counter()\n",
    "    files_downloaded_list = []\n",
    "    failed_to_download_list = []\n",
    "    file_list = []\n",
    "    files_downloaded_count = 0\n",
    "    total_count = 0\n",
    "    files_to_check_for = (\".HEIC\", \".heic\",\".jpeg\", \".JPEG\", \".JPG\", \".jpg\")\n",
    "    for folder_location in source_locations:\n",
    "        file_list = []\n",
    "        for root, dirs, files in os.walk(folder_location, topdown=False):\n",
    "            print(\"                                                                                                                                                                                                                                                                                         \", end =\"\\r\")\n",
    "            print(\"Folder being checked = \" + root, end =\"\\r\")\n",
    "            for filename in files:\n",
    "                if filename.lower().endswith(files_to_check_for) == True:\n",
    "                    full_file_path = os.path.join(root, filename)\n",
    "                    if os.path.getsize(full_file_path) > smallest_image_size:\n",
    "                        file_list.append(full_file_path)\n",
    "        total_count = len(file_list) + total_count\n",
    "        print(\"\\n\")\n",
    "        for photo in file_list:\n",
    "            files_downloaded_count += 1\n",
    "            file_extension = \".JPEG\"\n",
    "            photo_exif = get_image_coordinates(photo)\n",
    "            date_str = photo_exif[0]\n",
    "            if date_str != '':\n",
    "                try:\n",
    "                    date_format = '%Y:%m:%d %H:%M:%S'\n",
    "                    date_obj = datetime.strptime(date_str, date_format)\n",
    "                    new_filename = format(datetime.timestamp(date_obj),\".3f\") + file_extension\n",
    "                except:\n",
    "                    try:\n",
    "                        new_filename = \"CRC.\" + get_hash(photo) + file_extension  \n",
    "                    except:\n",
    "                        #Handles over length paths\n",
    "                        failed_to_download_list.append(photo_filename)\n",
    "                        pass\n",
    "            else:\n",
    "                try:\n",
    "                    new_filename = \"CRC.\" + get_hash(photo) + file_extension\n",
    "                except:\n",
    "                    #Handles over length paths\n",
    "                    failed_to_download_list.append(photo_filename)\n",
    "                    pass\n",
    "            if photo_exif[1] != 0 and photo_exif[2] != 0:\n",
    "                photo_filename = os.path.join(destination_folder, new_filename)\n",
    "                try:\n",
    "                    img = PILImage.open(photo)\n",
    "                    image_exif = img.getexif()\n",
    "                    image_exif.update({41728: photo})\n",
    "                    img.format = 'jpeg'\n",
    "                    if not os.path.exists(photo_filename):\n",
    "                        img.save(photo_filename, exif= image_exif, quality=75)\n",
    "                    files_downloaded_list.append(photo_filename)\n",
    "                except:\n",
    "                    failed_to_download_list.append(photo_filename)\n",
    "                    print(\"Problem saving to drive = \" + photo_filename, end =\"\\r\")\n",
    "                    pass\n",
    "            print(\"Crawled Photos downloaded = \" + str(files_downloaded_count) + \" of \" + str(total_count) + \"                                   \", end =\"\\r\")\n",
    "    print(\"\\nCrawled photos full download complete! Now run 'quick_photo_csv' or 'full_photo_csv'.\")\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Time taken: {(toc - tic)/60:0.4f} minutes\")\n",
    "    return()\n",
    "\n",
    "def copy_found_images(images_found, path):\n",
    "    for images in images_found:\n",
    "        source = images[1]\n",
    "        #print(\"images =\" + source)\n",
    "        #print(\"path=\" + path)\n",
    "        destination = path +  \"\\\\\" + images[0] + \"\\\\\" + os.path.basename(source)\n",
    "        if not os.path.exists(destination):\n",
    "            os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
    "            try:\n",
    "                #print(source, destination)\n",
    "                shutil.copy(source, destination)\n",
    "                print('Image copied succesfully to: ' + destination +\"                                                                         \" , end =\"\\r\")\n",
    "            except shutil.SameFileError:\n",
    "                attempt=0\n",
    "                while attempt <= 10:\n",
    "                    attempt +=1\n",
    "                    destination=destination+'-(same_name_'+str(attempt)+')'\n",
    "                print(\"Source and destination represents the same file. Not copied: \", source)\n",
    "            except:\n",
    "                print(\"Error occurred while copying file. Not copied: \", source)  \n",
    "    print(\"Copy found_images - Done!\")\n",
    "  \n",
    "def write_list_to_disk(raw_list, paths, file_name_prefix):\n",
    "    for path in paths:\n",
    "        if os.path.exists(path):\n",
    "            sys_timestamp=time.time()\n",
    "            file_name=\"%s-%s.csv\" % (file_name_prefix, sys_timestamp)\n",
    "            csv_file_name=os.path.join(path, file_name)\n",
    "            with open(csv_file_name,\"w\", newline='') as csv_file:\n",
    "                write = csv.writer(csv_file)\n",
    "                write.writerows(raw_list)\n",
    "            print(\"Image list sucessfully written to disk at %s\" % csv_file_name)\n",
    "        else:\n",
    "            print(\"Path not accessible for writing\" + path)\n",
    "\n",
    "def write_master_to_disk(raw_list, paths, file_name):\n",
    "    for path in paths:\n",
    "        if os.path.exists(path):\n",
    "            sys_timestamp=time.time()\n",
    "            file_name=\"%s.csv\" % (file_name)\n",
    "            csv_file_name=os.path.join(path, file_name)\n",
    "            with open(csv_file_name,\"w\", newline='') as csv_file:\n",
    "                write = csv.writer(csv_file)\n",
    "                write.writerows(raw_list)\n",
    "            print(\"Image list sucessfully written to disk at %s\" % csv_file)\n",
    "        else:\n",
    "            print(\"Path not accessible for writing\" + path)\n",
    "            \n",
    "def find_any_image_files(root_paths):\n",
    "    file_list=[]\n",
    "    for root_path in root_paths:\n",
    "        if os.path.exists(root_path):\n",
    "            print(\"Root path is found: \" + root_path)\n",
    "            print('Busy looking for images')\n",
    "            for (root,dirs,files) in os.walk(root_path, topdown=1): \n",
    "                for file in files:\n",
    "                    if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        file_found_with_path=os.path.join(root, file)\n",
    "                        file_list.append([file_found_with_path])\n",
    "            print('Done')\n",
    "        else:\n",
    "            print(\"Root path is not found. Please check path accessibility: \" + root_path)\n",
    "    return(file_list)\n",
    "\n",
    "def decimal_coords(coords, ref):\n",
    "    decimal_degrees = coords[0] + coords[1] / 60 + coords[2] / 3600\n",
    "    if ref == 'S' or ref == 'W':\n",
    "        decimal_degrees = -decimal_degrees\n",
    "    return decimal_degrees\n",
    "\n",
    "def image_coordinates(image_list):\n",
    "    GPS_list=[]\n",
    "    for img_path in image_list:\n",
    "        image_file=img_path[0]\n",
    "        print(image_file)\n",
    "        fail = 0\n",
    "        try:\n",
    "            with open(image_file, 'rb') as src:\n",
    "                img = Image(src)\n",
    "                date=('')\n",
    "                coords=(0,0)\n",
    "                if img.has_exif:\n",
    "                    try:\n",
    "                        date = img.datetime_original\n",
    "                    except:\n",
    "                        pass\n",
    "                    try:\n",
    "                        coords_lat = decimal_coords(img.gps_latitude,img.gps_latitude_ref)\n",
    "                        coords_long = decimal_coords(img.gps_longitude,img.gps_longitude_ref)\n",
    "                    except AttributeError:\n",
    "                        print ('No Coordinates')\n",
    "                        fail=1\n",
    "                    if fail != 1:\n",
    "                        GPS_list.append([src.name, date, coords_long, coords_lat])\n",
    "                        print(f\"Image {src.name}, Was taken: {img.datetime_original}, and has coordinates: {coords_lat}, {coords_long}\")\n",
    "                else:\n",
    "                    print ('The Image has no EXIF information')\n",
    "        except:\n",
    "            print('Image not valid '+ image_file)\n",
    "    return GPS_list\n",
    "\n",
    "def find_images_in_kml(kml_file, csv_file):\n",
    "    print(\"Running find_images_in_kml\")\n",
    "    tic = time.perf_counter()\n",
    "    my_sites = gpd.list_layers(kml_file) \n",
    "    image_found_list=[]\n",
    "    for layer in my_sites.name:\n",
    "        my_map = gpd.read_file(kml_file, driver='KML', layer = layer)\n",
    "        #print(my_map)\n",
    "        last_found_photo = 0\n",
    "        for i in range(0, len(my_map)):\n",
    "            x=0\n",
    "            folder = os.path.join(layer, my_map.Name.loc[i])\n",
    "            #print(folder)\n",
    "            # open file in read mode\n",
    "            with open(csv_file, 'r') as read_obj:\n",
    "                # pass the file object to reader() to get the reader object\n",
    "                csv_reader = reader(read_obj)\n",
    "                # Iterate over each row in the csv using reader object\n",
    "                my_pass=0\n",
    "                last_found_photo = 0\n",
    "                for row in csv_reader:\n",
    "                    if my_pass > 0:\n",
    "                        # row variable is a list that represents a row in csv\n",
    "                        p1=Point(float(row[5]),float(row[4]))\n",
    "                        check = my_map.contains(p1) #.values\n",
    "                        #print(check)\n",
    "                        if check[i]==True:\n",
    "                            datetime_taken = row[3]\n",
    "                            if datetime_taken == \"\":\n",
    "                                datetime_taken = \"1971:01:01 00:00:00\"\n",
    "                            date_time_obj=datetime.strptime(datetime_taken, '%Y:%m:%d %H:%M:%S')\n",
    "                            date_str = date_time_obj.strftime(\"%Y-%m-%d\")\n",
    "                            directory = os.path.join(folder,date_str)\n",
    "                            #print(directory)\n",
    "                            print(directory + \"                                        \", end =\"\\r\")\n",
    "                            image_found_list.append([directory,row[2]]) \n",
    "                            last_found_photo = date_time_obj.timestamp()\n",
    "                        else:\n",
    "                            datetime_taken = row[3]\n",
    "                            if datetime_taken != \"\":\n",
    "                                date_time_obj=datetime.strptime(datetime_taken, '%Y:%m:%d %H:%M:%S')\n",
    "                                if abs(last_found_photo - date_time_obj.timestamp()) < 300:\n",
    "                                    date_str = date_time_obj.strftime(\"%Y-%m-%d\")\n",
    "                                    directory = os.path.join(folder,date_str)\n",
    "                                    print(directory + \"                                        \", end =\"\\r\")\n",
    "                                    #print(abs(last_found_photo - date_time_obj.timestamp()))\n",
    "                                    image_found_list.append([directory,row[2]]) ##\n",
    "                    my_pass = 1\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"Time taken: {(toc - tic)/60:0.4f} minutes\")\n",
    "    return(image_found_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: THEN SET PHOTO FOLDER LOCATION AND iCLOUD LOGIN CREDENTIALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Authentication credentials and setting photo location folders\n",
    "\n",
    "#iCloud credentials\n",
    "username = 'cdegouveia@rocketmail.com'\n",
    "password = 'carisaCDG@3340'\n",
    "\n",
    "#General settings\n",
    "smallest_image_size = 250000\n",
    "\n",
    "#Photo crawling locations\n",
    "crawl_photo_sources = [\"\\\\\\\\192.168.1.10\\\\File_cabinet\\\\Carlos\"]\n",
    "\n",
    "#Specify the KML file\n",
    "kml_file='E:\\\\_system\\\\GPS Locations for Python.kml'\n",
    "\n",
    "#Specify the CSV file containing the image list and the respective GPS coordinates.\n",
    "#Make sure the CSV names corresponds with the file name specified during the master file creation process\n",
    "csv_file='E:\\\\_system\\\\GPS_image_list_master.csv'\n",
    "\n",
    "#Specify destination folder where the selected images will be copied to\n",
    "destination_folder=('E:\\\\FOUND_IMAGES')\n",
    "\n",
    "#Photo location folders\n",
    "unsupported_file_location = \"E:\\\\_unsupported_files\"\n",
    "system_file_location = \"E:\\\\_system\"\n",
    "crawl_photo_destination = 'E:\\\\PHOTO_LIBRARY_CRAWL'\n",
    "iphoto_folder_destination = 'E:\\\\PHOTO_LIBRARY_ICLOUD'\n",
    "\n",
    "#Check folders exist\n",
    "if not os.path.exists(unsupported_file_location):\n",
    "    os.makedirs(unsupported_file_location)\n",
    "if not os.path.exists(system_file_location):\n",
    "    os.makedirs(system_file_location)\n",
    "if not os.path.exists(crawl_photo_destination):\n",
    "    os.makedirs(crawl_photo_destination)\n",
    "if not os.path.exists(iphoto_folder_destination):\n",
    "    os.makedirs(iphoto_folder_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: COME HERE TO DOWNLOAD PHOTOS FROM iCLOUD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download NEW photos from iPhoto album. Quickest!\n",
    "#This can run in the background as the CSV file will not be updated automatically.\n",
    "api = icloud_initiate(username = username, password = password) #Login to iCloud\n",
    "download_new_icloud_photos(iphoto_folder_destination, api)\n",
    "convert_images_to_JPEG(iphoto_folder_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Download MISSING photos from iPhoto album. Not the quickest. This will a little time to complete!\n",
    "#This can run in the background as the CSV file will not be updated automatically.\n",
    "api = icloud_initiate(username = username, password = password) #Login to iCloud\n",
    "download_missing_icloud_photos(iphoto_folder_destination, api)\n",
    "convert_images_to_JPEG(iphoto_folder_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Download FULL content of iPhoto album. This is SLOW!!! This will take many hours to complete!\n",
    "#This can run in the background as the CSV file will not be updated automatically.\n",
    "api = icloud_initiate(username = username, password = password) #Login to iCloud\n",
    "download_all_icloud_photos_again(iphoto_folder_destination, api)\n",
    "convert_images_to_JPEG(iphoto_folder_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: (OPTIONAL) COME HERE TO CRAWL FOR PHOTOS FROM NAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crawl_for_images(destination_folder = crawl_photo_destination, source_locations = crawl_photo_sources)\n",
    "convert_images_to_JPEG(crawl_photo_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5: PHOTO CONVERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert iPhoto to JPEG\n",
    "convert_images_to_JPEG(iphoto_folder_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert Blackbox to JPEG\n",
    "convert_images_to_JPEG(crawl_photo_destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6: COME HERE TO UPDATE .CSV PHOTO REGISTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Check the photo register for missing photos. Quickest!\n",
    "quick_photo_csv([iphoto_folder_destination, crawl_photo_destination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Do a full refresh of the photo register. Not the quickest. This will take a couple hours!\n",
    "full_photo_csv([iphoto_folder_destination, crawl_photo_destination])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7: USE THIS TO PARSE THE KML FILE AND FIND THE MATCHING IMAGES IN THE CSV AND THEN COPY THE IMAGES TO THE DESTINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this to locate images within the KML polygons.\n",
    "#The images will be collected from the source destinations (make sure\n",
    "#the destination folders are accessible) and copied to the destination folder.\n",
    "\n",
    "#Sift through the list of GPS coordinates. If an image falls within a KML\n",
    "#polygon, then put it into a list.\n",
    "qualifying_image_list=find_images_in_kml(kml_file, csv_file)\n",
    "\n",
    "#Take the list and use it to copy the qualifying images to their respective folders.\n",
    "#The folders names coorespond with the polygon names created with GOOGLE Earth.\n",
    "#The KML file can hold several polygons. Each polygon must have a unique name.\n",
    "copy_found_images(qualifying_image_list, destination_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OR STEP 3: COME HERE TO PERFORM A DAILY TYPICAL QUICK 'NEW iPHOTO'S DOWNLOAD, A QUICK REGISTER UPDATE, A KML PARSE AND FINALLY A PHOTOS FOUND DISK COPY'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New iPhotos found on icloud = 0 (Checking: 501 of 35367)\n",
      "New photos download done! Now run 'quick_photo_csv' or 'full_photo_csv'.\n",
      "Running convert_images_to_JPEG\n",
      "Files found on E:\\PHOTO_LIBRARY_ICLOUD: 35345\n",
      "Analysing folder\n",
      "Files converted to JPEG: 0 of 5\n",
      "Files that were not converted = 5, moved to E:\\_unsupported_files: \n",
      "1651403582.816.PNG\n",
      "1606983960.000.mp4\n",
      "1525354390.000.png\n",
      "1512065435.044.PNG\n",
      "1512065201.636.PNG\n",
      "Running quick_photo_csv\n",
      "Opened 'GPS_image_list_master.csv'. Looking for missed records.\n",
      "Files found on E:\\PHOTO_LIBRARY_ICLOUD: 35340\n",
      "Checking file 35340 of 35340. New JPG or MOV files found = 0\n",
      "Updated photo register written to 'GPS_image_list_master.csv'.\n",
      "Time taken: 3.5449 minutes\n",
      "Running find_images_in_kml\n",
      "Time taken: 4.8215 minutes4-07-11                                                                          \n",
      "Copy found_images - Done!\n",
      "Copy found_images - Done!\n",
      "TOTAL Time taken: 11.9098 minutes\n"
     ]
    }
   ],
   "source": [
    "#Use this for day to day use\n",
    "tic = time.perf_counter() #Start Time taken timer\n",
    "api = icloud_initiate(username = username, password = password)                        #Login to iCloud\n",
    "download_new_icloud_photos(iphoto_folder_destination, api)                             #Download photos\n",
    "convert_images_to_JPEG(iphoto_folder_destination)                                      #Convert downloaded photos to my standard format\n",
    "quick_photo_csv([iphoto_folder_destination])                                           #Update CSV file with new photos and GPS\n",
    "qualifying_image_list=find_images_in_kml(kml_file, csv_file)                           #Parse the CSV to find photos that fall in the KML polygons\n",
    "destination_folder=('E:\\\\FOUND_IMAGES')                                                #Copy found photos to USB\n",
    "copy_found_images(qualifying_image_list, destination_folder)\n",
    "destination_folder=('D:\\\\OneDrive - Department of Premier Western Cape\\\\Site Photos')  #Copy found photos to onedrive\n",
    "copy_found_images(qualifying_image_list, destination_folder)\n",
    "print(f\"TOTAL Time taken: {(time.perf_counter() - tic)/60:0.4f} minutes\") #Time taken result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NOTES FOR FUTURE IMPROVEMENT\n",
    "- remove requirement for module EXIF\n",
    "- Save blackbox photos to seperate directories named after the crawl sources\n",
    "- have a csv feature that looks in the directory source folder of the photo and check if there is a kml in order to fill missing GPS coordinates\n",
    "- Introduce a feature that removes obsolete photos (that were deleted from iphone or blackbox)\n",
    "- When doing a CSV registration, maybe instead of specifying the folders it needs to check, instead do a crawl of the drive looking for JPEG images, and ignore the _unsupported_files folder\n",
    "- When downloading iCloud, and checking if files exists before saving, maybe check _unsupported_files folder as well (not just the main folder). Preventing a save of an existing image will prevent overwriting any new exif data this app wrote to the image\n",
    "- Introduce a 'Learn' feature where the images are updated from changes to the CSV.\n",
    "- Intrduce CSV feature that automatically populates GPS coordinates according to likely co-ordinates based on neighbouring images. Tthen apply the 'Learn' feature. This way the original images don't need to be modified.\n",
    "- When a CSV is updated, save the previous CSV as a revision so that errors can be rolled back\n",
    "- Someteims when the app runs, warnings appear. See if these can be handled.\n",
    "- The Full CSV does not pick up MOV files, while the quick CSV picks them up. I think the Full CSV should also pick up MOV in order to get them approximate GPS coordinates\n",
    "- MOV files have 'media created' exif. Does python see this as 'date taken'? It seems like it does, but maybe it is the EXIF module that does this automatically and might not work if PIL EXIF is used because it might be a different tag\n",
    "- Consider combining all photos (blackbox and ios) into one folder so that duplicates are not saved\n",
    "- Create a feature that creates kml and popuplates these pins on to google earth, maybe including photos. Maybe moving the pins to use the learn feature to modify the CSV and the affected photo in the usb drive.\n",
    "- Checking whether a file is already prsent in the drive or in the CSV list can be improved using a binomial sort alglorith. Taking too long to perform 'quick csv check'\n",
    "- In crawl algorithm, the chçheck if file in csv exsts' might not be working\n",
    "- The subroutines must test for presence of drive. All the try's trigger the print \"Corrucpt....\" line  \n",
    "- Binomial search algorith. Apply this to all search algorithms, including the GPS search algorith.\n",
    "- Something wrong with quick CSV. Didn't pick up new 1000's additions from crawl.\n",
    "- For crawl, maybe argument should be a single target folder at a time instead of a list of folders.\n",
    "- For population of missing GPS coords, rather copy the missing coords to the CSV and then use learn feature to send it back to the usb drives images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
